Required tools
* [MikuMikuDance](http://www.geocities.jp/higuchuu4)
* [MMDBridge](https://sites.google.com/a/render.jp/mmdbridge/)
* [MikuMikuMoving](https://sites.google.com/site/mikumikumoving/)

Assets
* https://bowlroll.net/file/4576

Tutorial
* [3D初心者が作ったMikuMikuDance初心者向け講座](http://www.nicovideo.jp/mylist/7374894)
* [Blender](http://hellamerdurial.blogspot.com/2014/02/mmd-blender.html)

Engine Integration
* [Unity](https://www.slideshare.net/flashscope/mmd-unity1)
* [UE4](http://unrealengine.hatenablog.com/entry/2016/01/11/224331)
  * [IM4U Plugin](https://github.com/bm9/IM4U/tree/4.10.X)
  * [IM4U Plugin Src](https://github.com/bm9/UnrealEngine_IM4UPlugin)

Shader
* https://github.com/ray-cast/ray-mmd

Animation
* http://on-demand.gputechconf.com/gtc/2017/presentation/s7289-paul-kruszewski-human-motion-capture-from-2d-video-using-cloud-based-cnns.pdf
* [Example-Guided Deep Reinforcement Learning of Physics-Based Character Skills](https://xbpeng.github.io/projects/DeepMimic/index.html)
* [A DEEP LEARNING FRAMEWORK FOR CHARACTER MOTION SYNTHESIS AND EDITING](http://www.gameanim.com/2016/05/22/deep-learning-framework-character-motion-synthesis-editing/)
  * [pdf](http://www.ipab.inf.ed.ac.uk/cgvu/motionsynthesis.pdf)
* [Recurrent Neural Networks for Modeling Motion Capture Data](https://www.eurasip.org/Proceedings/Eusipco/Eusipco2017/wpapers/DL2.pdf)
* [AI powered motion capture](https://getrad.co/)
  * https://www.forbes.com/sites/nvidia/2018/05/09/ai-powered-motion-capture-a-radical-step-toward-modern-3d-content-pipelines/#70d838d5b551
* [Monocular Human Motion Capture
using a CNN Coupled with a Geometric Prior](https://arxiv.org/pdf/1701.02354.pdf)
