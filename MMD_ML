
Motion Capture using ML
* [This Reinforcement Learning Algorithm Can Capture Motion and Recreate It](https://arxiv.org/pdf/1810.03599.pdf)
* [Creating custom Fortnite dances with webcam and Deep Learning](https://towardsdatascience.com/creating-custom-fortnite-dances-with-webcam-and-deep-learning-9b1a236c1b59)
* [Classification of K-Pop Dance Movements Based on
Skeleton Information Obtained by a Kinect Sensor](https://pdfs.semanticscholar.org/d0a1/12f02818a57f3a10364d555c8c40bdfabbcd.pdf)
* [3D Human Motion Capture from 2D Video using Cloud-Based CNNs](http://on-demand.gputechconf.com/gtc/2017/presentation/s7289-paul-kruszewski-human-motion-capture-from-2d-video-using-cloud-based-cnns.pdf)
* [Example-Guided Deep Reinforcement Learning of Physics-Based Character Skills](https://xbpeng.github.io/projects/DeepMimic/index.html)
* [AI powered motion capture](https://getrad.co/)
  * https://www.forbes.com/sites/nvidia/2018/05/09/ai-powered-motion-capture-a-radical-step-toward-modern-3d-content-pipelines/#70d838d5b551
* [Monocular Human Motion Capture
using a CNN Coupled with a Geometric Prior](https://arxiv.org/pdf/1701.02354.pdf)
* [Human motion prediction](https://github.com/una-dinosauria/human-motion-prediction)
* [Recurrent Neural Networks for Modeling Motion Capture Data](https://www.eurasip.org/Proceedings/Eusipco/Eusipco2017/wpapers/DL2.pdf)

Using CMU Motion Capture Database
* [CMU Motion Capture Database](http://mocap.cs.cmu.edu)
  * [motion data file format](http://www.dcs.shef.ac.uk/intranet/research/public/resmes/CS0111.pdf)
  * [How to convert BVH to VMD](https://github.com/powroupi/blender_mmd_tools/wiki/Tutorial:-How-to-convert-BVH-to-VMD)
    * http://www6.atwiki.jp/vpvpwiki/pages/218.html#id_8e4d9a75
      * https://github.com/esetomo/mio
  * Auto Conditioned RNN motion
    * https://www.youtube.com/watch?v=FunMxjmDIQM&feature=youtu.be?t=0s
      * https://arxiv.org/pdf/1707.05363.pdf
      * https://github.com/hjzh4/Auto-Conditioned-LSTM (tensor flow version)
      * https://github.com/papagina/Auto_Conditioned_RNN_motion (original pytorch version)
  * [A DEEP LEARNING FRAMEWORK FOR CHARACTER MOTION SYNTHESIS AND EDITING](http://www.gameanim.com/2016/05/22/deep-learning-framework-character-motion-synthesis-editing/)
    * [pdf](http://www.ipab.inf.ed.ac.uk/cgvu/motionsynthesis.pdf)
    * https://github.com/AliJalalifar/Character_Animation
  * [Lecture: RNN and autoencoder: pdf](https://www.google.co.kr/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=2ahUKEwj8rNb5kuzeAhXJTLwKHbG5BKwQFjAAegQIChAC&url=https%3A%2F%2Fcanvas.stanford.edu%2Ffiles%2F1079044%2Fdownload%3Fdownload_frd%3D1&usg=AOvVaw2uZMJCvtEE6eQHGcypWqev)
  * [LSTM-autoencoder](https://github.com/iwyoo/LSTM-autoencoder)

Dancing motion generation
* [Learn Audio Beat Tracking for Music Information Retrieval](https://www.analyticsvidhya.com/blog/2018/02/audio-beat-tracking-for-music-information-retrieval/)
* [Machine-Learning Algorithm Watches Dance Dance Revolution, Then Creates Dances of Its Own](https://www.technologyreview.com/s/604000/machine-learning-algorithm-watches-dance-dance-revolution-then-creates-dances-of-its-own/)
* [Sequential Deep Learning for Dancing Motion Generation](http://www.osaka-kyoiku.ac.jp/~challeng/SIG-Challenge-046/SIG-Challenge-046-08.pdf)
* [Music-Driven Dance Generation with Neural Networks](https://omid.al/projects/GrooveNet.html)
  * [essentia](https://github.com/MTG/essentia/blob/master/src/examples/tutorial/essentia_python_tutorial.ipynb)
* https://medium.com/@kcimc/discrete-figures-7d9e9c275c47
* [Deep Learning Dance Smackdown](http://silky.github.io/posts/2017-08-28-deep-learning-dance-smackdown.html)
